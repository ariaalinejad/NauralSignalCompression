{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.fftpack import idct\n",
    "from sklearn.decomposition import PCA\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "s0 = np.load('../test_data_sintef.npy') # 48kHz (Dataset 1)\n",
    "s1 = np.load('../52728_2021-09-25_01_24KHz_test_data_sintef.npy') # 24kHz (Dataset 2)\n",
    "s2 = np.load('../56180_2021-11-05_06_24KHz_test_data_sintef.npy') # 24kHz (Dataset 3)\n",
    "s3 = np.load('../61467_2022-09-16_01_48KHz_test_data_sintef.npy') # 48kHz (Dataset 4)\n",
    "\n",
    "# calculate min num bits we need to allocate to the original\n",
    "bO = len(bin(np.max(np.abs(s0)).astype(int))[2:]) # should always be 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band Pass (0.1-5000Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp48(temp):\n",
    "    # Digital Low pass and high pass filters -> to replicate bandpass filtering with INTAN\n",
    "    Fs = 48000\n",
    "    fc1 = 5000\n",
    "    fc2 = 0.1\n",
    "    Wn1 = fc1 / (Fs/2)\n",
    "    Wn2 = fc2 / (Fs/2)\n",
    "    b3, a3 = butter(N=3, Wn=Wn1, btype='low', analog=False, output='ba')\n",
    "    b4, a4 = butter(N=1, Wn=Wn2, btype='high', analog=False, output='ba')\n",
    "\n",
    "    # First band pass filter the signal (using what resembles the analog filters in the INTAN chip)\n",
    "    lp = np.zeros_like(temp) # low-passed signal\n",
    "    bp = np.zeros_like(temp) # band-passed signal\n",
    "    for i in range(temp.shape[1]):\n",
    "        lp[:,i] = lfilter(b3,a3, temp[:,i]) \n",
    "        bp[:,i] = lfilter(b4,a4,lp[:,i])\n",
    "    \n",
    "\n",
    "    # scale to use 16 bit if needed\n",
    "    #bp = np.clip(bp, -32768, 32767) \n",
    "    if np.max(np.abs(bp))>32767:\n",
    "        bp = (bp/(np.max(np.abs(bp)))) * 32767 \n",
    "\n",
    "    return bp.astype(int) # return the band pass filtered signal\n",
    "\n",
    "def bp24(temp):\n",
    "    # Digital Low pass and high pass filters -> to replicate bandpass filtering with INTAN\n",
    "    Fs = 24000\n",
    "    fc1 = 5000\n",
    "    fc2 = 0.1\n",
    "    Wn1 = fc1 / (Fs/2)\n",
    "    Wn2 = fc2 / (Fs/2)\n",
    "    b3, a3 = butter(N=3, Wn=Wn1, btype='low', analog=False, output='ba')\n",
    "    b4, a4 = butter(N=1, Wn=Wn2, btype='high', analog=False, output='ba')\n",
    "\n",
    "    # First band pass filter the signal (using what resembles the analog filters in the INTAN chip)\n",
    "    lp = np.zeros_like(temp)\n",
    "    bp = np.zeros_like(temp)\n",
    "    for i in range(temp.shape[1]):\n",
    "        lp[:,i] = lfilter(b3,a3, temp[:,i]) \n",
    "        bp[:,i] = lfilter(b4,a4,lp[:,i])\n",
    "    \n",
    "    # make sure to not use more then 16 bit on output data\n",
    "    #bp = np.clip(bp, -32768, 32767) \n",
    "    if np.max(np.abs(bp))>32767:\n",
    "        bp = (bp/(np.max(np.abs(bp)))) * 32767 \n",
    "\n",
    "    return bp.astype(int) # return the band pass filtered signal\n",
    "\n",
    "def bp20(temp):\n",
    "    # Digital Low pass and high pass filters -> to replicate bandpass filtering with INTAN\n",
    "    Fs = 20000\n",
    "    fc1 = 5000\n",
    "    fc2 = 0.1\n",
    "    Wn1 = fc1 / (Fs/2)\n",
    "    Wn2 = fc2 / (Fs/2)\n",
    "    b3, a3 = butter(N=3, Wn=Wn1, btype='low', analog=False, output='ba')\n",
    "    b4, a4 = butter(N=1, Wn=Wn2, btype='high', analog=False, output='ba')\n",
    "\n",
    "    # First band pass filter the signal (using what resembles the analog filters in the INTAN chip)\n",
    "    lp = np.zeros_like(temp)\n",
    "    bp = np.zeros_like(temp)\n",
    "    for i in range(temp.shape[1]):\n",
    "        lp[:,i] = lfilter(b3,a3, temp[:,i]) \n",
    "        bp[:,i] = lfilter(b4,a4,lp[:,i])\n",
    "\n",
    "    return bp.astype(int) # return the band pass filtered signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Down Sample to 20kHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample from 48kHz to 20kHz\n",
    "def down48(temp):\n",
    "    Fs = 48000\n",
    "    frac = Fs/20000\n",
    "    d = np.zeros((int(temp.shape[0]/frac), temp.shape[1]))# new down sampled signal\n",
    "    for i in range(int(temp.shape[0]/frac)):\n",
    "        d[i,:] = temp[int(frac*i),:]\n",
    "\n",
    "    return d.astype(int)\n",
    "\n",
    "# down sample from 24kHz to 20kHz\n",
    "def down24(temp):\n",
    "    Fs = 24000\n",
    "    frac = Fs/20000\n",
    "    d = np.zeros((int(temp.shape[0]/frac), temp.shape[1]))# new down sampled signal\n",
    "    for i in range(int(temp.shape[0]/frac)):\n",
    "        d[i,:] = temp[int(frac*i),:]\n",
    "\n",
    "    return d.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothen (FIR filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_smoothen4(temp):\n",
    "    counter = 0 \n",
    "    reset = 5 # how many samples to wait before resetting output\n",
    "    \n",
    "    p = 4 # num past samples to take mean of\n",
    "\n",
    "    lst = [0]*p # list of current and past samples \n",
    "\n",
    "    meanSignal = np.zeros(temp.shape) # mean of current and past samples\n",
    "\n",
    "    for i in range(len(temp)):\n",
    "        counter += 1\n",
    "        lst.pop() # remove the last element of the list\n",
    "        lst.insert(0, temp[i]) # insert the current sample value at the start of the list\n",
    "\n",
    "        meanSignal[i] = np.sum(lst)/p # mean of p past values\n",
    "\n",
    "        # after reset samples, send the original sample instead of the mean\n",
    "        if counter == reset:\n",
    "            meanSignal[i] = temp[i]\n",
    "            counter = 0\n",
    "        \n",
    "    return meanSignal\n",
    "\n",
    "\n",
    "def smoothen4_c(temp):\n",
    "    SM = []\n",
    "    for i in range(temp.shape[1]): # loop through all channels\n",
    "        sm = i_smoothen4(temp[:,i])\n",
    "        SM.append(sm)\n",
    "        \n",
    "    SM = np.array(SM).T\n",
    "\n",
    "    return SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# without reset\\ndef i_smoothen4(temp):\\n    p = 4 # num past samples to take mean of\\n\\n    lst = [0]*p # list of current and past samples \\n\\n    meanSignal = np.zeros(temp.shape) # mean of current and past samples\\n\\n    for i in range(len(temp)):\\n        lst.pop() # remove the last element of the list\\n        lst.insert(0, temp[i]) # insert the current sample value at the start of the list\\n        \\n        meanSignal[i] = np.round(np.sum(lst)/p) # mean of p past values\\n            \\n        \\n    return meanSignal.astype(int)\\n\\n\\ndef smoothen4_c(temp):\\n    SM = []\\n    for i in range(temp.shape[1]): # loop through all channels\\n        sm = i_smoothen4(temp[:,i])\\n        SM.append(sm)\\n        \\n    SM = np.array(SM).T\\n\\n    return SM.astype(int)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# without reset\n",
    "def i_smoothen4(temp):\n",
    "    p = 4 # num past samples to take mean of\n",
    "\n",
    "    lst = [0]*p # list of current and past samples \n",
    "\n",
    "    meanSignal = np.zeros(temp.shape) # mean of current and past samples\n",
    "\n",
    "    for i in range(len(temp)):\n",
    "        lst.pop() # remove the last element of the list\n",
    "        lst.insert(0, temp[i]) # insert the current sample value at the start of the list\n",
    "        \n",
    "        meanSignal[i] = np.round(np.sum(lst)/p) # mean of p past values\n",
    "            \n",
    "        \n",
    "    return meanSignal.astype(int)\n",
    "\n",
    "\n",
    "def smoothen4_c(temp):\n",
    "    SM = []\n",
    "    for i in range(temp.shape[1]): # loop through all channels\n",
    "        sm = i_smoothen4(temp[:,i])\n",
    "        SM.append(sm)\n",
    "        \n",
    "    SM = np.array(SM).T\n",
    "\n",
    "    return SM.astype(int)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_smoothen4(temp):\n",
    "    counter = 0 \n",
    "    reset = 5 # how many samples to wait before resetting output\n",
    "\n",
    "    p = 4 # num past samples to take mean of\n",
    "\n",
    "    pastSignal = [0]*(p-1) # remember p-1 past signals\n",
    "\n",
    "    predictedSignal = np.zeros(temp.shape) # reconstruction of original signal\n",
    "\n",
    "    for i in range(len(temp)):\n",
    "        counter += 1\n",
    "\n",
    "        predictedSignal[i] = temp[i]*p - np.sum(pastSignal) # reconstruct the original using p-1 past samples and transmitted mean\n",
    "\n",
    "        if counter == reset:\n",
    "            counter = 0\n",
    "            predictedSignal[i] = temp[i]\n",
    "            \n",
    "        pastSignal.pop() # remove too old past sample\n",
    "        pastSignal.insert(0, predictedSignal[i]) # insert new predict as next past sample\n",
    "        \n",
    "    return predictedSignal\n",
    "\n",
    "# outputs the reconstructed signal\n",
    "def u_smoothen4_c(temp): \n",
    "    predict = []\n",
    "    for i in range(temp.shape[1]): # loop through all channels\n",
    "        pred = j_smoothen4(temp[:,i])\n",
    "        predict.append(pred)\n",
    "        \n",
    "    predict = np.array(predict).T\n",
    "\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# without reset\\ndef j_smoothen4(temp):\\n    p = 4 # num past samples to take mean of\\n\\n    pastSignal = [0]*(p-1) # remember p-1 past signals\\n\\n    predictedSignal = np.zeros(temp.shape) # reconstruction of original signal\\n\\n    for i in range(len(temp)):\\n        predictedSignal[i] = np.round(temp[i]*p - np.sum(pastSignal)) # reconstruct the original using p-1 past samples and transmitted mean\\n            \\n        pastSignal.pop() # remove too old past sample\\n        pastSignal.insert(0, predictedSignal[i]) # insert new predict as next past sample\\n        \\n    return predictedSignal.astype(int)\\n\\n# outputs the reconstructed signal\\ndef u_smoothen4_c(temp): \\n    predict = []\\n    for i in range(temp.shape[1]): # loop through all channels\\n        pred = j_smoothen4(temp[:,i])\\n        predict.append(pred)\\n        \\n    predict = np.array(predict).T\\n\\n    return predict.astype(int)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# without reset\n",
    "def j_smoothen4(temp):\n",
    "    p = 4 # num past samples to take mean of\n",
    "\n",
    "    pastSignal = [0]*(p-1) # remember p-1 past signals\n",
    "\n",
    "    predictedSignal = np.zeros(temp.shape) # reconstruction of original signal\n",
    "\n",
    "    for i in range(len(temp)):\n",
    "        predictedSignal[i] = np.round(temp[i]*p - np.sum(pastSignal)) # reconstruct the original using p-1 past samples and transmitted mean\n",
    "            \n",
    "        pastSignal.pop() # remove too old past sample\n",
    "        pastSignal.insert(0, predictedSignal[i]) # insert new predict as next past sample\n",
    "        \n",
    "    return predictedSignal.astype(int)\n",
    "\n",
    "# outputs the reconstructed signal\n",
    "def u_smoothen4_c(temp): \n",
    "    predict = []\n",
    "    for i in range(temp.shape[1]): # loop through all channels\n",
    "        pred = j_smoothen4(temp[:,i])\n",
    "        predict.append(pred)\n",
    "        \n",
    "    predict = np.array(predict).T\n",
    "\n",
    "    return predict.astype(int)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_dpcm(temp):\n",
    "    previousSample = 0 # initial predicted value\n",
    "\n",
    "    residual = np.zeros_like(temp) # residual signal\n",
    "\n",
    "    for i in range(len(temp)): \n",
    "        residual[i] = temp[i] - previousSample # residual is true - predict\n",
    "\n",
    "        previousSample = temp[i] # reconstruct by adding residual to past sample\n",
    "    \n",
    "    return  residual\n",
    "\n",
    "def dpcm_d(temp):\n",
    "    residual = []\n",
    "    for i in range(temp.shape[1]): # loop through all channels\n",
    "        res = i_dpcm(temp[:,i])\n",
    "        residual.append(res)\n",
    "    \n",
    "    residual = np.array(residual).T\n",
    "\n",
    "    return residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_dpcm(temp):\n",
    "    previousSample = 0 # initial predicted value\n",
    "\n",
    "    predict = np.zeros_like(temp) # reconstructed signal\n",
    "\n",
    "    for i in range(len(temp)): \n",
    "\n",
    "        previousSample = previousSample + temp[i] # reconstruct by adding residual to past sample\n",
    "        \n",
    "        predict[i] = previousSample # predicted value is set to be the past sample\n",
    "    return predict\n",
    "\n",
    "# output reconstruct\n",
    "def u_dpcm_d(temp):\n",
    "    predict = []\n",
    "    for i in range(temp.shape[1]): # loop through all channels\n",
    "        pred = j_dpcm(temp[:,i])\n",
    "        predict.append(pred)\n",
    "    \n",
    "    predict = np.array(predict).T\n",
    "\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCM\n",
    "def i_pcm(temp):\n",
    "    #previousSample = 0 # initial predicted value\n",
    "    counter = 0 \n",
    "    reset = 5#200 # how many samples to wait before resetting output\n",
    "\n",
    "    p = 4\n",
    "\n",
    "    lst = [0]*p # list of past samples\n",
    "\n",
    "    residual = np.zeros_like(temp) # residual signal\n",
    "\n",
    "    for i in range(len(temp)): \n",
    "        counter += 1\n",
    "        \n",
    "        predict = np.sum(lst)/p\n",
    "\n",
    "        residual[i] = temp[i] - predict # residual is true - predict\n",
    "\n",
    "        #previousSample = temp[i] # reconstruct by adding residual to past sample\n",
    "\n",
    "        if counter == reset:\n",
    "            counter = 0\n",
    "            #residual[i] = temp[i] - lst[0]\n",
    "            residual[i] = temp[i]\n",
    "\n",
    "        lst.pop()\n",
    "        lst.insert(0,temp[i])\n",
    "\n",
    "    return  residual\n",
    "\n",
    "def pcm_n(temp):\n",
    "    residual = []\n",
    "    for i in range(temp.shape[1]): # loop through all channels\n",
    "        res = i_pcm(temp[:,i])\n",
    "        residual.append(res)\n",
    "    \n",
    "    residual = np.array(residual).T\n",
    "\n",
    "    return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_pcm(temp):\n",
    "    counter = 0 \n",
    "    reset = 5 #200 # how many samples to wait before resetting output\n",
    "\n",
    "    p = 4\n",
    "\n",
    "    pastSignal = [0]*p\n",
    "\n",
    "    predict = np.zeros_like(temp) # reconstructed signal\n",
    "\n",
    "    for i in range(len(temp)): \n",
    "        counter += 1\n",
    "\n",
    "        predict[i] = np.sum(pastSignal)/p + temp[i] # reconstruct by adding residual to past sample\n",
    "\n",
    "        if counter == reset:\n",
    "            counter = 0\n",
    "            predict[i] = temp[i] \n",
    "            #predict[i] = temp[i] + pastSignal[0]\n",
    "        \n",
    "        pastSignal.pop()\n",
    "        pastSignal.insert(0,predict[i])\n",
    "    return predict\n",
    "\n",
    "# output reconstruct\n",
    "def u_pcm_n(temp):\n",
    "    predict = []\n",
    "    for i in range(temp.shape[1]): # loop through all channels\n",
    "        pred = j_pcm(temp[:,i])\n",
    "        predict.append(pred)\n",
    "    \n",
    "    predict = np.array(predict).T\n",
    "\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS Stereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_stereo(temp): \n",
    "    channelPairs = [[0,1],[2,3],[4,5],[6,7],[8,9], [10,11], [12,13], [14,15]] # compare the channels closest to each other\n",
    "\n",
    "    S = np.zeros([temp.shape[0],int(temp.shape[1]/2)])\n",
    "    D = np.zeros([temp.shape[0],int(temp.shape[1]/2)])\n",
    "\n",
    "    k = 0\n",
    "    for i in channelPairs:\n",
    "        # encode\n",
    "        S[:,k] = 0.5*(temp[:,i[0]] + temp[:,i[1]]) # take avg. of all samples of the two channels\n",
    "        D[:,k] = 0.5*(temp[:,i[0]] - temp[:,i[1]]) # take diff. of all samples of the two channels\n",
    "        \n",
    "        k += 1\n",
    "    return D, S\n",
    "\n",
    "def stereo_e(temp):\n",
    "    D, S = i_stereo(temp)\n",
    "\n",
    "    DS = np.concatenate((D,S),1)\n",
    "\n",
    "    return DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_stereo(temp): \n",
    "    channelPairs = [[0,1],[2,3],[4,5],[6,7],[8,9], [10,11], [12,13], [14,15]] # compare the channels closest to each other\n",
    "    \n",
    "    S = np.zeros([temp.shape[0],int(temp.shape[1]/2)])\n",
    "    D = np.zeros([temp.shape[0],int(temp.shape[1]/2)])\n",
    "    predict = np.zeros_like(temp)\n",
    "\n",
    "    D, S = np.split(temp, 2, axis=1)\n",
    "\n",
    "    k = 0\n",
    "    for i in channelPairs:\n",
    "        \n",
    "        # decode\n",
    "        predict[:,i[0]] = S[:,k] + D[:,k] # reconstruct original channels\n",
    "        predict[:,i[1]] = S[:,k] - D[:,k]\n",
    "        \n",
    "        k += 1\n",
    "    return predict\n",
    "\n",
    "def u_stereo_e(temp):\n",
    "    predict = j_stereo(temp)\n",
    "\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS Quadro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# atempt to reduce rounding error:\\ndef i_quadro(temp): \\n    channelQuartets = [[0,1,2,3],[4,5,6,7],[8,9,10,11]] # compare the channels closes to each other: LFP/AP\\n    channelPairs = [[12,13], [14,15]] # compare the channels closes to each other: EcoG and EMG\\n\\n    # initialize\\n    Q1 = np.zeros([temp.shape[0],3])\\n    Q2 = np.zeros([temp.shape[0],3])\\n    Q3 = np.zeros([temp.shape[0],3])\\n    Q4 = np.zeros([temp.shape[0],3])\\n    \\n    S = np.zeros([temp.shape[0],2])\\n    D = np.zeros([temp.shape[0],2])\\n\\n    k = 0 # counting channels in one quartet\\n    for i in channelQuartets:\\n        # encode\\n        Q1[:,k] = np.round(0.25*(temp[:,i[0]] + temp[:,i[1]] + temp[:,i[2]] + temp[:,i[3]]))\\n        Q2[:,k] = np.round(0.25*(temp[:,i[0]] - temp[:,i[1]] - temp[:,i[2]] + temp[:,i[3]])*4)\\n        Q3[:,k] = np.round(0.25*(temp[:,i[0]] - temp[:,i[1]] + temp[:,i[2]] - temp[:,i[3]])*4)\\n        Q4[:,k] = np.round(0.25*(temp[:,i[0]] + temp[:,i[1]] - temp[:,i[2]] - temp[:,i[3]])*4)\\n\\n        k += 1\\n    \\n    k = 0 # counting channles in one duo\\n    for i in channelPairs:\\n        # encode\\n        S[:,k] = np.round(0.5*(temp[:,i[0]] + temp[:,i[1]]))\\n        D[:,k] = np.round(0.5*(temp[:,i[0]] - temp[:,i[1]])*2)\\n\\n        k += 1\\n    \\n\\n    Q = np.concatenate((Q1,Q2,Q3,Q4,D,S),1)\\n\\n    return Q.astype(int)\\n\\ndef quadro_j(temp):\\n    Q = i_quadro(temp)\\n\\n    return Q.astype(int)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def i_quadro(temp): \n",
    "    channelQuartets = [[0,1,2,3],[4,5,6,7],[8,9,10,11]] # compare the channels closes to each other: LFP/AP\n",
    "    channelPairs = [[12,13], [14,15]] # compare the channels closes to each other: EcoG and EMG\n",
    "\n",
    "    # initialize\n",
    "    Q1 = np.zeros([temp.shape[0],3])\n",
    "    Q2 = np.zeros([temp.shape[0],3])\n",
    "    Q3 = np.zeros([temp.shape[0],3])\n",
    "    Q4 = np.zeros([temp.shape[0],3])\n",
    "    \n",
    "    S = np.zeros([temp.shape[0],2])\n",
    "    D = np.zeros([temp.shape[0],2])\n",
    "\n",
    "    k = 0 # counting channels in one quartet\n",
    "    for i in channelQuartets:\n",
    "        # encode\n",
    "        Q1[:,k] = 0.25*(temp[:,i[0]] + temp[:,i[1]] + temp[:,i[2]] + temp[:,i[3]])\n",
    "        Q2[:,k] = 0.25*(temp[:,i[0]] - temp[:,i[1]] - temp[:,i[2]] + temp[:,i[3]])\n",
    "        Q3[:,k] = 0.25*(temp[:,i[0]] - temp[:,i[1]] + temp[:,i[2]] - temp[:,i[3]])\n",
    "        Q4[:,k] = 0.25*(temp[:,i[0]] + temp[:,i[1]] - temp[:,i[2]] - temp[:,i[3]])\n",
    "\n",
    "        k += 1\n",
    "    \n",
    "    k = 0 # counting channles in one duo\n",
    "    for i in channelPairs:\n",
    "        # encode\n",
    "        S[:,k] = 0.5*(temp[:,i[0]] + temp[:,i[1]])\n",
    "        D[:,k] = 0.5*(temp[:,i[0]] - temp[:,i[1]])\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    Q = np.concatenate((Q1,Q2,Q3,Q4,D,S),1)\n",
    "\n",
    "    return Q\n",
    "\n",
    "def quadro_j(temp):\n",
    "    Q = i_quadro(temp)\n",
    "\n",
    "    return Q\n",
    "\n",
    "'''# atempt to reduce rounding error:\n",
    "def i_quadro(temp): \n",
    "    channelQuartets = [[0,1,2,3],[4,5,6,7],[8,9,10,11]] # compare the channels closes to each other: LFP/AP\n",
    "    channelPairs = [[12,13], [14,15]] # compare the channels closes to each other: EcoG and EMG\n",
    "\n",
    "    # initialize\n",
    "    Q1 = np.zeros([temp.shape[0],3])\n",
    "    Q2 = np.zeros([temp.shape[0],3])\n",
    "    Q3 = np.zeros([temp.shape[0],3])\n",
    "    Q4 = np.zeros([temp.shape[0],3])\n",
    "    \n",
    "    S = np.zeros([temp.shape[0],2])\n",
    "    D = np.zeros([temp.shape[0],2])\n",
    "\n",
    "    k = 0 # counting channels in one quartet\n",
    "    for i in channelQuartets:\n",
    "        # encode\n",
    "        Q1[:,k] = np.round(0.25*(temp[:,i[0]] + temp[:,i[1]] + temp[:,i[2]] + temp[:,i[3]]))\n",
    "        Q2[:,k] = np.round(0.25*(temp[:,i[0]] - temp[:,i[1]] - temp[:,i[2]] + temp[:,i[3]])*4)\n",
    "        Q3[:,k] = np.round(0.25*(temp[:,i[0]] - temp[:,i[1]] + temp[:,i[2]] - temp[:,i[3]])*4)\n",
    "        Q4[:,k] = np.round(0.25*(temp[:,i[0]] + temp[:,i[1]] - temp[:,i[2]] - temp[:,i[3]])*4)\n",
    "\n",
    "        k += 1\n",
    "    \n",
    "    k = 0 # counting channles in one duo\n",
    "    for i in channelPairs:\n",
    "        # encode\n",
    "        S[:,k] = np.round(0.5*(temp[:,i[0]] + temp[:,i[1]]))\n",
    "        D[:,k] = np.round(0.5*(temp[:,i[0]] - temp[:,i[1]])*2)\n",
    "\n",
    "        k += 1\n",
    "    \n",
    "\n",
    "    Q = np.concatenate((Q1,Q2,Q3,Q4,D,S),1)\n",
    "\n",
    "    return Q.astype(int)\n",
    "\n",
    "def quadro_j(temp):\n",
    "    Q = i_quadro(temp)\n",
    "\n",
    "    return Q.astype(int)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# atempt to reduce rounding error:\\ndef j_quadro(temp): \\n    channelQuartets = [[0,1,2,3],[4,5,6,7],[8,9,10,11]] # compare the channels closes to each other: LFP/AP\\n    channelPairs = [[12,13], [14,15]] # compare the channels closes to each other: EcoG and EMG\\n\\n    predict = np.zeros_like(temp)\\n\\n    split1, split2, split3, split4 = np.split(temp, 4, axis=1)\\n    split5 = np.concatenate((split1, split2, split3), axis=1)\\n    Q1,Q2,Q3,Q4 = np.split(split5, 4, axis=1)\\n    D,S = np.split(split4, 2, axis=1)\\n\\n    Q2,Q3,Q4 = 0.25*Q2, 0.25*Q3, 0.25*Q4\\n    D = 0.5*D\\n\\n    k = 0 # counting channels in one quartet\\n    for i in channelQuartets:\\n\\n        # decode\\n        predict[:,i[0]] = np.round((Q1[:,k] + Q2[:,k] + Q3[:,k] + Q4[:,k]))\\n        predict[:,i[1]] = np.round((Q1[:,k] - Q2[:,k] - Q3[:,k] + Q4[:,k]))\\n        predict[:,i[2]] = np.round((Q1[:,k] - Q2[:,k] + Q3[:,k] - Q4[:,k]))\\n        predict[:,i[3]] = np.round((Q1[:,k] + Q2[:,k] - Q3[:,k] - Q4[:,k]))\\n\\n        k += 1\\n    \\n    k = 0 # counting channles in one duo\\n    for i in channelPairs:\\n        \\n        # decode\\n        predict[:,i[0]] = np.round((S[:,k] + D[:,k]))\\n        predict[:,i[1]] = np.round((S[:,k] - D[:,k]))\\n        \\n        k += 1\\n\\n    return predict.astype(int)\\n\\ndef u_quadro_j(temp):\\n    predict = j_quadro(temp)\\n\\n    return predict.astype(int)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def j_quadro(temp): \n",
    "    channelQuartets = [[0,1,2,3],[4,5,6,7],[8,9,10,11]] # compare the channels closes to each other: LFP/AP\n",
    "    channelPairs = [[12,13], [14,15]] # compare the channels closes to each other: EcoG and EMG\n",
    "\n",
    "    predict = np.zeros_like(temp)\n",
    "\n",
    "    split1, split2, split3, split4 = np.split(temp, 4, axis=1)\n",
    "    split5 = np.concatenate((split1, split2, split3), axis=1)\n",
    "    Q1,Q2,Q3,Q4 = np.split(split5, 4, axis=1)\n",
    "    D,S = np.split(split4, 2, axis=1)\n",
    "\n",
    "    k = 0 # counting channels in one quartet\n",
    "    for i in channelQuartets:\n",
    "\n",
    "        # decode\n",
    "        predict[:,i[0]] = (Q1[:,k] + Q2[:,k] + Q3[:,k] + Q4[:,k])\n",
    "        predict[:,i[1]] = (Q1[:,k] - Q2[:,k] - Q3[:,k] + Q4[:,k])\n",
    "        predict[:,i[2]] = (Q1[:,k] - Q2[:,k] + Q3[:,k] - Q4[:,k])\n",
    "        predict[:,i[3]] = (Q1[:,k] + Q2[:,k] - Q3[:,k] - Q4[:,k])\n",
    "\n",
    "        k += 1\n",
    "    \n",
    "    k = 0 # counting channles in one duo\n",
    "    for i in channelPairs:\n",
    "        \n",
    "        # decode\n",
    "        predict[:,i[0]] = (S[:,k] + D[:,k])\n",
    "        predict[:,i[1]] = (S[:,k] - D[:,k])\n",
    "        \n",
    "        k += 1\n",
    "\n",
    "    return predict\n",
    "\n",
    "def u_quadro_j(temp):\n",
    "    predict = j_quadro(temp)\n",
    "\n",
    "    return predict\n",
    "\n",
    "'''# atempt to reduce rounding error:\n",
    "def j_quadro(temp): \n",
    "    channelQuartets = [[0,1,2,3],[4,5,6,7],[8,9,10,11]] # compare the channels closes to each other: LFP/AP\n",
    "    channelPairs = [[12,13], [14,15]] # compare the channels closes to each other: EcoG and EMG\n",
    "\n",
    "    predict = np.zeros_like(temp)\n",
    "\n",
    "    split1, split2, split3, split4 = np.split(temp, 4, axis=1)\n",
    "    split5 = np.concatenate((split1, split2, split3), axis=1)\n",
    "    Q1,Q2,Q3,Q4 = np.split(split5, 4, axis=1)\n",
    "    D,S = np.split(split4, 2, axis=1)\n",
    "\n",
    "    Q2,Q3,Q4 = 0.25*Q2, 0.25*Q3, 0.25*Q4\n",
    "    D = 0.5*D\n",
    "\n",
    "    k = 0 # counting channels in one quartet\n",
    "    for i in channelQuartets:\n",
    "\n",
    "        # decode\n",
    "        predict[:,i[0]] = np.round((Q1[:,k] + Q2[:,k] + Q3[:,k] + Q4[:,k]))\n",
    "        predict[:,i[1]] = np.round((Q1[:,k] - Q2[:,k] - Q3[:,k] + Q4[:,k]))\n",
    "        predict[:,i[2]] = np.round((Q1[:,k] - Q2[:,k] + Q3[:,k] - Q4[:,k]))\n",
    "        predict[:,i[3]] = np.round((Q1[:,k] + Q2[:,k] - Q3[:,k] - Q4[:,k]))\n",
    "\n",
    "        k += 1\n",
    "    \n",
    "    k = 0 # counting channles in one duo\n",
    "    for i in channelPairs:\n",
    "        \n",
    "        # decode\n",
    "        predict[:,i[0]] = np.round((S[:,k] + D[:,k]))\n",
    "        predict[:,i[1]] = np.round((S[:,k] - D[:,k]))\n",
    "        \n",
    "        k += 1\n",
    "\n",
    "    return predict.astype(int)\n",
    "\n",
    "def u_quadro_j(temp):\n",
    "    predict = j_quadro(temp)\n",
    "\n",
    "    return predict.astype(int)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCT temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_dctt(temp):\n",
    "    #pp = 400 # window of samples analyzed\n",
    "    pp = 500 # window of samples analyzed\n",
    "    D = np.zeros((pp, pp))\n",
    "\n",
    "    # generate DCT basis\n",
    "    c_0 = np.sqrt(1/pp)\n",
    "    c_k = np.sqrt(2/pp)\n",
    "    for k in range(pp):\n",
    "        if (k == 0):\n",
    "            D[:, k] = [c_0*np.cos(k*np.pi*(2*n+1)/(2*pp)) for n in range(pp)] \n",
    "        else:\n",
    "            D[:, k] = [c_k*np.cos(k*np.pi*(2*n+1)/(2*pp)) for n in range(pp)]\n",
    "        D[:, k] = D[:, k] / np.linalg.norm(D[:, k], ord = 2) \n",
    "\n",
    "    nSteps = int(temp.shape[0]/pp)\n",
    "    c_mat = np.zeros((pp, nSteps, temp.shape[1])) # matrix of coefficients\n",
    "\n",
    "    for j in range(temp.shape[1]):\n",
    "        for i in range(nSteps):\n",
    "            c_mat[:,i,j] = D.T@temp[pp*i:pp*i + pp, j] # calculate coefficients by multiplying DCT matrix\n",
    "\n",
    "    return c_mat\n",
    "\n",
    "def dctt_f(temp):\n",
    "    c_mat = i_dctt(temp)\n",
    "\n",
    "    c_mat_flat = np.zeros((c_mat.shape[0]*c_mat.shape[1], c_mat.shape[2]))\n",
    "    for i in range(c_mat_flat.shape[1]):\n",
    "        c_mat_flat[:,i] = c_mat[:,:,i].reshape((c_mat.shape[0]*c_mat.shape[1])) # flatten coefficient matrix to match shape of signal\n",
    "\n",
    "    return c_mat_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_dctt(temp):\n",
    "    pp = temp.shape[0]\n",
    "    D = np.zeros((pp, pp))\n",
    "\n",
    "    # generate DCT basis\n",
    "    for k in range(pp):\n",
    "        a = np.zeros(pp)\n",
    "        a[k] = 1\n",
    "        D[:, k] = idct(a, norm='ortho') # use idct on the atom\n",
    "\n",
    "    d_hat = np.zeros((temp.shape[0]*temp.shape[1], temp.shape[2]))\n",
    "\n",
    "    for j in range(temp.shape[2]): \n",
    "        for i in range(temp.shape[1]):\n",
    "            d_hat[pp*i:pp*i + pp, j] = D@temp[:,i,j]\n",
    "        \n",
    "    return d_hat\n",
    "\n",
    "def u_dctt_f(temp):\n",
    "    pp = 500\n",
    "    #pp = 400\n",
    "    nSteps = int(temp.shape[0]/pp)\n",
    "    c_mat = np.zeros((pp, nSteps, temp.shape[1])) # matrix of coefficients\n",
    "\n",
    "    for i in range(temp.shape[1]):\n",
    "        c_mat[:,:,i] = temp[:,i].reshape((pp,nSteps)) \n",
    "\n",
    "    d_hat = j_dctt(c_mat)\n",
    "\n",
    "    return d_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCT spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_dcts(temp):\n",
    "    pp = temp.shape[1] # take DCT across channels, for one sample at a time\n",
    "    D = np.zeros((pp, pp))\n",
    "\n",
    "    # generate DCT basis (can be built beforehand)\n",
    "    c_0 = np.sqrt(1/pp)\n",
    "    c_k = np.sqrt(2/pp)\n",
    "    for k in range(pp):\n",
    "        if (k == 0):\n",
    "            D[:, k] = [c_0*np.cos(k*np.pi*(2*n+1)/(2*pp)) for n in range(pp)] \n",
    "        else:\n",
    "            D[:, k] = [c_k*np.cos(k*np.pi*(2*n+1)/(2*pp)) for n in range(pp)]\n",
    "        D[:, k] = D[:, k] / np.linalg.norm(D[:, k], ord = 2) \n",
    "\n",
    "    c = np.zeros((temp.shape[1], temp.shape[0])) # coefficient matrix\n",
    "    \n",
    "    for i in range(temp.shape[0]):\n",
    "        c[:, i] = D.T@temp[i,:] # calcualte coefficients by multilying DCT matrix with signal\n",
    "\n",
    "    return c\n",
    "\n",
    "def dcts_g(temp):\n",
    "\n",
    "    c = i_dcts(temp).T\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_dcts(temp):\n",
    "    pp = temp.shape[1] # take DCT across channels, for one sample at a time\n",
    "    D = np.zeros((pp, pp))\n",
    "\n",
    "    # generate DCT basis\n",
    "    for k in range(pp):\n",
    "        a = np.zeros(pp)\n",
    "        a[k] = 1\n",
    "        D[:, k] = idct(a, norm='ortho') # use idct on the atom\n",
    "\n",
    "    d_hat = np.zeros((temp.shape[1], temp.shape[0])) # coefficient matrix\n",
    "    \n",
    "    for i in range(temp.shape[0]):\n",
    "        d_hat[:, i] = D@temp[i,:] # calcualte coefficients by multilying DCT matrix with signal\n",
    "\n",
    "    return d_hat\n",
    "\n",
    "def u_dcts_g(temp):\n",
    "\n",
    "    d_hat = j_dcts(temp).T\n",
    "\n",
    "    return d_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_pca(temp): \n",
    "    v = np.zeros((temp.shape[1], temp.shape[0])) # coefficient matrix\n",
    "    \n",
    "    pp = 500 # look at 400 past samples\n",
    "    nSteps = int(temp.shape[0]/pp)\n",
    "    pca_vec = []\n",
    "  \n",
    "    for i in range(nSteps):\n",
    "        pca = PCA()\n",
    "        v[:, pp*i:pp*i + pp] = pca.fit_transform(temp[pp*i:pp*i + pp,:]).T # calculate coefficients\n",
    "        pca_vec.append(pca)\n",
    "        \n",
    "    return v, pca_vec\n",
    "\n",
    "def pca_h(temp):\n",
    "    v,pca_vec = i_pca(temp)\n",
    "\n",
    "    return v.T, pca_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_pca(temp, pca_vec):\n",
    "    d_hat = np.zeros_like(temp.T)\n",
    "    \n",
    "    pp = 500\n",
    "    nSteps = int(temp.shape[1]/pp)\n",
    "  \n",
    "    for i in range(nSteps):\n",
    "        pca = pca_vec[i]\n",
    "        d_hat[pp*i:pp*i + pp, :] = pca.inverse_transform(temp[:, pp*i:pp*i + pp].T)\n",
    "\n",
    "    return d_hat\n",
    "\n",
    "def u_pca_h(temp, pca_vec):\n",
    "    d_hat = j_pca(temp, pca_vec)\n",
    "\n",
    "    return d_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel mean removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_chmean(temp):\n",
    "\n",
    "    output = np.zeros((temp.shape[0], temp.shape[1] + 1))\n",
    "    for i in range(temp.shape[1]):\n",
    "        output[:,i] =  temp[:,i] - np.mean(temp, axis=1) \n",
    "    output[:,-1] =     np.mean(temp, axis=1) \n",
    "\n",
    "    return output\n",
    "\n",
    "def chmean_m(temp):\n",
    "    output = i_chmean(temp)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_chmean(temp):\n",
    "\n",
    "    output = np.zeros((temp.shape[0], temp.shape[1]-1))\n",
    "    for i in range(temp.shape[1]-1):\n",
    "        output[:,i] = temp[:,i] + temp[:,-1]\n",
    "\n",
    "    return output\n",
    "\n",
    "def u_chmean_m(temp):\n",
    "    output = j_chmean(temp)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# written with the help of GPT4\n",
    "class HuffmanNode:\n",
    "    def __init__(self, value=None, frequency=0):\n",
    "        self.value = value\n",
    "        self.frequency = frequency\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.frequency < other.frequency\n",
    "\n",
    "def build_frequency_table(data):\n",
    "    frequency_table = defaultdict(int)\n",
    "    for num in data:\n",
    "        frequency_table[num] += 1\n",
    "    \n",
    "    all_values = np.arange(-32768, 32768) # values between -32768 and 32768\n",
    "\n",
    "    for value in all_values: \n",
    "        if not frequency_table[value]:\n",
    "            frequency_table[value] = 0.5 # makes sure that values that have not been seen yet also get a value (would be implemented differently in hardware)\n",
    "    \n",
    "\n",
    "    return frequency_table\n",
    "\n",
    "def build_huffman_tree(frequency_table):\n",
    "    priority_queue = [HuffmanNode(value, freq) for value, freq in frequency_table.items()]\n",
    "    heapq.heapify(priority_queue)\n",
    "\n",
    "    while len(priority_queue) > 1:\n",
    "        left_node = heapq.heappop(priority_queue)\n",
    "        right_node = heapq.heappop(priority_queue)\n",
    "\n",
    "        parent_node = HuffmanNode(frequency=left_node.frequency + right_node.frequency)\n",
    "        parent_node.left = left_node\n",
    "        parent_node.right = right_node\n",
    "\n",
    "        heapq.heappush(priority_queue, parent_node)\n",
    "\n",
    "    return heapq.heappop(priority_queue)\n",
    "\n",
    "def build_encoding_table(huffman_tree):\n",
    "    encoding_table = {}\n",
    "    def traverse(node, code):\n",
    "        if node.value is not None:\n",
    "            encoding_table[node.value] = code\n",
    "        else:\n",
    "            traverse(node.left, code + \"0\")\n",
    "            traverse(node.right, code + \"1\")\n",
    "    traverse(huffman_tree, \"\")\n",
    "    return encoding_table\n",
    "\n",
    "def huffman_encode(data, encoding_table):\n",
    "\n",
    "    encoded_data = \"\"\n",
    "    for num in data:\n",
    "        encoded_data += encoding_table[num]\n",
    "\n",
    "    return encoded_data\n",
    "\n",
    "def huffman_decode(encoded_data, huffman_tree):\n",
    "    decoded_data = []\n",
    "    current_node = huffman_tree\n",
    "\n",
    "    for bit in encoded_data:\n",
    "        if bit == \"0\":\n",
    "            current_node = current_node.left\n",
    "        else:\n",
    "            current_node = current_node.right\n",
    "\n",
    "        if current_node.value is not None:\n",
    "            decoded_data.append(current_node.value)\n",
    "            current_node = huffman_tree\n",
    "\n",
    "    return decoded_data\n",
    "\n",
    "def huff_i(prepross, train_sig, temp):\n",
    "\n",
    "    #train_sig = train\n",
    "    for char in prepross: \n",
    "        match char: \n",
    "            case 'c':\n",
    "                train_sig = smoothen4_c(train_sig)\n",
    "            case 'd':\n",
    "                train_sig = dpcm_d(train_sig)\n",
    "            case 'e':\n",
    "                train_sig = stereo_e(train_sig)\n",
    "            case 'f':\n",
    "                train_sig = dctt_f(train_sig)\n",
    "            case 'g':\n",
    "                train_sig = dcts_g(train_sig)\n",
    "            case 'h':\n",
    "                train_sig,_ = pca_h(train_sig)\n",
    "            case 'j':\n",
    "                train_sig = quadro_j(train_sig)\n",
    "            case 'm': \n",
    "                train_sig = chmean_m(train_sig)\n",
    "\n",
    "    # train the huffman tree using the training set\n",
    "    frequency_table = build_frequency_table(train_sig.flatten())\n",
    "    huffman_tree = build_huffman_tree(frequency_table)\n",
    "    encoding_table = build_encoding_table(huffman_tree)\n",
    "\n",
    "    encoded = []\n",
    "    decoded = np.zeros_like(temp)\n",
    "    for i in range(temp.shape[1]):\n",
    "        #print('Channel: ' + str(i))\n",
    "        encoded_data = huffman_encode(temp[:,i], encoding_table)\n",
    "        encoded.append(encoded_data)\n",
    "\n",
    "        decoded[:,i] = np.array(huffman_decode(encoded_data, huffman_tree))\n",
    "\n",
    "\n",
    "\n",
    "    error = 0\n",
    "    lenOriginal = 0\n",
    "    lenHuff = 0\n",
    "    for j in range(temp.shape[1]):\n",
    "        error += np.sum(np.abs(decoded[:,j] - temp[:,j]))\n",
    "        lenHuff += len(encoded[j])\n",
    "        for i in range(temp.shape[0]):\n",
    "            lenOriginal += bO # 16 \n",
    "\n",
    "    if error > 0: \n",
    "        print('Error in Huffman coding!')\n",
    "\n",
    "    #print(f'Length of original signal: {lenOriginal}')\n",
    "    #print(f'Length of encoded signal: {lenHuff}')\n",
    "\n",
    "    RCR = (1 - lenHuff/lenOriginal) * 100\n",
    "    #print(f'Relatice Compression Ratio (RCR): {RCR:.2f}%')\n",
    "\n",
    "    return RCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-adaptive Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_rice_encode(values, K):\n",
    "    encoded_values = []\n",
    "\n",
    "    divisor = int(2**K)\n",
    "\n",
    "    for value in values:\n",
    "        sign_bit = \"1\" if value < 0 else \"0\"\n",
    "        abs_value = abs(value)\n",
    "\n",
    "        quotient = abs_value // divisor\n",
    "        remainder = abs_value % divisor\n",
    "\n",
    "        unary_code = \"1\" * quotient + \"0\"\n",
    "        binary_code = bin(remainder)[2:].zfill(divisor.bit_length() - 1)\n",
    "\n",
    "        encoded_values.append(sign_bit + unary_code + binary_code)\n",
    "\n",
    "    return encoded_values\n",
    "\n",
    "def i_rice_decode(encoded_values, K):\n",
    "    decoded_values = []\n",
    "\n",
    "    divisor = int(2**K)\n",
    "\n",
    "    for encoded_value in encoded_values:\n",
    "        sign_bit = encoded_value[0]\n",
    "        quotient = encoded_value[1:].index(\"0\") #+ 1\n",
    "        remainder = int(encoded_value[quotient + 1:], 2)\n",
    "\n",
    "        value = quotient * divisor + remainder\n",
    "        if sign_bit == \"1\":\n",
    "            value = -value\n",
    "\n",
    "        decoded_values.append(value)\n",
    "\n",
    "    return decoded_values\n",
    "\n",
    "def rice_k(prepross, train_sig, temp):\n",
    "\n",
    "\n",
    "    temp2 = train_sig # the training set\n",
    "    for char in prepross: \n",
    "        match char: \n",
    "            case 'c':\n",
    "                temp2 = smoothen4_c(temp2)\n",
    "            case 'd':\n",
    "                temp2 = dpcm_d(temp2)\n",
    "            case 'e':\n",
    "                temp2 = stereo_e(temp2)\n",
    "            case 'f':\n",
    "                temp2 = dctt_f(temp2)\n",
    "            case 'g':\n",
    "                temp2 = dcts_g(temp2)\n",
    "            case 'h':\n",
    "                temp2,_ = pca_h(temp2)\n",
    "            case 'j':\n",
    "                temp2 = quadro_j(temp2)\n",
    "            case 'm': \n",
    "                temp2 = chmean_m(temp2)\n",
    "\n",
    "    #m = round(np.log(2)*np.mean(np.abs(temp2))) # calculate best K based on training set\n",
    "\n",
    "    K = round( np.log2( np.log(2)*np.mean(np.abs(temp2)))) # calculate best K based on training set\n",
    "\n",
    "    # check if we use one or several channels\n",
    "    if temp.ndim == 1:\n",
    "        encoded = i_rice_encode(temp, K)\n",
    "        decoded = np.array(i_rice_decode(encoded, K))\n",
    "    else:\n",
    "        encoded = []\n",
    "        decoded = np.zeros_like(temp)\n",
    "        for i in range(temp.shape[1]):\n",
    "            encoded.append(i_rice_encode(temp[:,i], K))\n",
    "            decoded[:,i] = np.array(i_rice_decode(encoded[i], K))\n",
    "\n",
    "    error = 0\n",
    "    lenOriginal = 0\n",
    "    lenRice = 0\n",
    "\n",
    "    # check if we use one or several channels\n",
    "    if temp.ndim == 1:\n",
    "        error = np.sum(np.abs(decoded - temp))\n",
    "        for i in range(temp.shape[0]):\n",
    "            lenOriginal += bO \n",
    "            lenRice += len(encoded[i])\n",
    "\n",
    "    else: \n",
    "        for j in range(temp.shape[1]):\n",
    "            error += np.sum(np.abs(decoded[:,j] - temp[:,j]))\n",
    "            for i in range(temp.shape[0]):\n",
    "                lenOriginal += bO # 16 \n",
    "                lenRice += len(encoded[j][i])\n",
    "\n",
    "    if error > 0: \n",
    "        print('Error in Rice coding!')\n",
    "\n",
    "    RCR = (1 - lenRice/lenOriginal) * 100\n",
    "\n",
    "    return RCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adaptive Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_rice_encode_adaptive(values, K, alpha = 0.5):\n",
    "    encoded_values = []\n",
    "    window = 40\n",
    "\n",
    "    # look at window values at a time, update the divisor, and use this to perform rice coding on the window\n",
    "    for i in range(int(len(values)/window)):\n",
    "        if (i>0):\n",
    "            if (np.log(2)*np.mean(np.abs(values[(i-1)*window:(i-1)*window + window])) == 0):\n",
    "                K = 0 # since log2(0) is not possible\n",
    "            else:\n",
    "                K = np.round( alpha*np.log2(np.log(2)*np.mean(np.abs(values[(i-1)*window:(i-1)*window + window]))) + (1-alpha)*K )\n",
    "                if(K<0): \n",
    "                    K = 0\n",
    "        K = int(K)\n",
    "              \n",
    "        divisor = int(2**K) # can be impelented by right shifting\n",
    "\n",
    "        encoded_values.append(bin(K)[2:].zfill(4)) # send the K-value that is used\n",
    "\n",
    "        for value in values[i*window:i*window + window]: \n",
    "            sign_bit = \"1\" if value < 0 else \"0\"\n",
    "            abs_value = abs(value)\n",
    "\n",
    "            quotient = abs_value // divisor\n",
    "            remainder = abs_value % divisor\n",
    "\n",
    "            unary_code = \"1\" * quotient + \"0\"\n",
    "            binary_code = bin(remainder)[2:].zfill(divisor.bit_length() - 1)\n",
    "\n",
    "            encoded_values.append(sign_bit + unary_code + binary_code) # since the length of the remainder is know the sign bit position is also known (fist after)\n",
    "\n",
    "    #print('oki')\n",
    "    return encoded_values\n",
    "\n",
    "def i_rice_decode_adaptive(encoded_values):\n",
    "    decoded_values = []\n",
    "    window = 40\n",
    "    counter = 0\n",
    "\n",
    "    #divisor = int(2**K)\n",
    "\n",
    "    for encoded_value in encoded_values:\n",
    "        if counter == 0: \n",
    "            K = int(encoded_value, 2)\n",
    "            divisor = int(2**K)\n",
    "            counter = window\n",
    "        else:\n",
    "            counter -= 1\n",
    "\n",
    "            sign_bit = encoded_value[0]\n",
    "            quotient = encoded_value[1:].index(\"0\") #+ 1\n",
    "            remainder = int(encoded_value[quotient + 1:], 2)\n",
    "\n",
    "            value = quotient * divisor + remainder\n",
    "            if sign_bit == \"1\":\n",
    "                value = -value\n",
    "\n",
    "            decoded_values.append(value)\n",
    "\n",
    "    return decoded_values\n",
    "\n",
    "def rice_adaptive_l(prepross, train_sig, temp, alpha = 0.5):\n",
    "\n",
    "\n",
    "    temp2 = train_sig # the training set\n",
    "    for char in prepross: \n",
    "        match char: \n",
    "            case 'c':\n",
    "                temp2 = smoothen4_c(temp2)\n",
    "            case 'd':\n",
    "                temp2 = dpcm_d(temp2)\n",
    "            case 'e':\n",
    "                temp2 = stereo_e(temp2)\n",
    "            case 'f':\n",
    "                temp2 = dctt_f(temp2)\n",
    "            case 'g':\n",
    "                temp2 = dcts_g(temp2)\n",
    "            case 'h':\n",
    "                temp2, _ = pca_h(temp2)\n",
    "            case 'j':\n",
    "                temp2 = quadro_j(temp2)\n",
    "            case 'm': \n",
    "                temp2 = chmean_m(temp2)\n",
    "            case 'n': \n",
    "                temp2 = pcm_n(temp2)\n",
    "\n",
    "\n",
    "    K = round( np.log2( np.log(2)*np.mean(np.abs(temp2)))) # calculate best K based on training set\n",
    "\n",
    "    # check if we use one or several channels\n",
    "    if temp.ndim == 1:\n",
    "        encoded = i_rice_encode_adaptive(temp, K, alpha)\n",
    "        decoded = np.array(i_rice_decode_adaptive(encoded))\n",
    "    else:\n",
    "        encoded = []\n",
    "        decoded = np.zeros_like(temp)\n",
    "        for i in range(temp.shape[1]):\n",
    "            encoded.append(i_rice_encode_adaptive(temp[:,i], K, alpha))\n",
    "            decoded[:,i] = np.array(i_rice_decode_adaptive(encoded[i]))\n",
    "\n",
    "    error = 0\n",
    "    lenOriginal = 0\n",
    "    lenRice = 0\n",
    "\n",
    "    # check if we use one or several channels\n",
    "    if temp.ndim == 1:\n",
    "        error = np.sum(np.abs(decoded - temp))\n",
    "        for i in range(temp.shape[0]):\n",
    "            lenOriginal += bO\n",
    "            lenRice += len(encoded[i])\n",
    "    else: \n",
    "        for j in range(temp.shape[1]):\n",
    "            error += np.sum(np.abs(decoded[:,j] - temp[:,j]))\n",
    "            for i in range(temp.shape[0]):\n",
    "                lenOriginal += bO # 16 \n",
    "                lenRice += len(encoded[j][i])\n",
    "\n",
    "    if error>0: \n",
    "        ('Error in Rice coding!')\n",
    "\n",
    "    #print(f'Length of original signal: {lenOriginal}')\n",
    "    #print(f'Length of encoded signal: {lenRice}')\n",
    "\n",
    "    RCR = (1 - lenRice/lenOriginal) * 100\n",
    "\n",
    "    return RCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions: bp20/bp24/bp48, down24/down48, smoothen_c, dpcm_d, stereo_e, dctt_f, dcts_g, pca_h, huff_i, quadro_j, rice_k, rice_adaptive_l, chmean_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define signal\n",
    "N = 12000 #0.25s\n",
    "#N = 240000 #5s\n",
    "temp0 = s0[:,:].astype(int) # dataset to test on\n",
    "temp1 = s1[:,:].astype(int) # dataset to test on\n",
    "train = s2[:,:].astype(int) # dataset used for training\n",
    "\n",
    "test = s3[:,:].astype(int) # dataset used for final testing\n",
    "\n",
    "# Pre-process\n",
    "sig0      = down48(bp48(temp0)) \n",
    "sig1      = down24(bp24(temp1)) \n",
    "sig3      = down48(bp48(test)) \n",
    "train_sig = down24(bp24(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define functions (with bp20 at end (removed)), and .astype(int) added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in the combinations of methods to be tested prints RCR, relative error and SNDR\n",
    "def result(alg, train_sig, temp, alpha=0.5, plot=False):\n",
    "\n",
    "    sig = temp\n",
    "    Fs = 20000\n",
    "\n",
    "\n",
    "    if alg not in ('k', 'l', 'i'):\n",
    "        for char in alg: \n",
    "            match char: \n",
    "                case 'c':\n",
    "                    temp = smoothen4_c(temp)\n",
    "                case 'd':\n",
    "                    temp = dpcm_d(temp)\n",
    "                case 'e':\n",
    "                    temp = stereo_e(temp)\n",
    "                case 'f':\n",
    "                    temp = dctt_f(temp)\n",
    "                case 'g':\n",
    "                    temp = dcts_g(temp)\n",
    "                case 'h':\n",
    "                    temp, pca_vec = pca_h(temp)\n",
    "                case 'j':\n",
    "                    temp = quadro_j(temp)\n",
    "                case 'm': \n",
    "                    temp = chmean_m(temp)\n",
    "                case 'n': \n",
    "                    temp = pcm_n(temp)\n",
    "            \n",
    "        '''if np.max(np.abs(temp*10))<=32767:\n",
    "            #temp = temp*10\n",
    "            #sig = sig*10\n",
    "            print(int(np.max(np.abs(temp))))\n",
    "            temp = int( (temp/int(np.max(np.abs(temp)))) * 32767 ) # scale signal down to 16 bit\n",
    "        else: \n",
    "            #temp = temp*10\n",
    "            #sig = sig*10\n",
    "            #print('Attention!')'''\n",
    "        \n",
    "        '''if np.max(np.abs(temp))>32767:\n",
    "            temp = (temp/int(np.max(np.abs(temp)))) * 32767  # scale signal down to 16 bit\n",
    "            scale = int(np.max(np.abs(temp)))\n",
    "            #sig = (sig/scale) * 32767'''\n",
    "        temp = np.round(temp).astype(int) # temp solution <.--------------------------------------------------------------------------\n",
    "        if alpha == '':\n",
    "\n",
    "            # calculate RCR\n",
    "            bC = len(bin(np.max(np.abs(temp)))[2:])\n",
    "\n",
    "            RCR = (1 - bC/bO) * 100\n",
    "\n",
    "            print(f'RCR of {alg}: {RCR:.2f}')     \n",
    "        elif alpha == 'H':\n",
    "            print(f\"RCR of {alg}: {huff_i(alg, train_sig, temp):.2f}\") # test pre-training Huffman (non-adaptive)\n",
    "        else:\n",
    "            print(f\"RCR of {alg}: {rice_adaptive_l(alg, train_sig, temp, alpha):.2f}\") # Rice with learning rate alpha\n",
    "           \n",
    "        # re-construct signal, to calculate error\n",
    "        temp2 = temp\n",
    "        for char in alg[::-1]: \n",
    "            match char: \n",
    "                case 'c':\n",
    "                    temp2 = u_smoothen4_c(temp2)\n",
    "                case 'd':\n",
    "                    temp2 = u_dpcm_d(temp2)\n",
    "                case 'e':\n",
    "                    temp2 = u_stereo_e(temp2)\n",
    "                case 'f':\n",
    "                    temp2 = u_dctt_f(temp2)\n",
    "                case 'g':\n",
    "                    temp2 = u_dcts_g(temp2)\n",
    "                case 'h':\n",
    "                    temp2 = u_pca_h(temp2.T, pca_vec)\n",
    "                case 'j':\n",
    "                    temp2 = u_quadro_j(temp2)\n",
    "                case 'm': \n",
    "                    temp2 = u_chmean_m(temp2)\n",
    "                case 'n': \n",
    "                    temp2 = u_pcm_n(temp2)\n",
    "\n",
    "        # Filter the re-constructed signal to be within the band of interest\n",
    "        temp2 = bp20(temp2) # <------------------------------------------------------------------------------------------------------\n",
    "        sig = bp20(sig) # <------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        total_error = np.sum(np.abs(temp2.flatten().astype(np.float32) - sig.flatten().astype(np.float32)))\n",
    "        #total_sig = sum(abs(sig.flatten().astype(np.float32)))\n",
    "        #ratio = (total_error/total_sig)*100\n",
    "        #print(f'Rounding error: {ratio:.2f}%')\n",
    "\n",
    "        SNDR = 0\n",
    "        if total_error != 0:\n",
    "            for i in range(sig.shape[1]):\n",
    "                SNDR += 1/(sig.shape[1]) * 20*np.log10(np.linalg.norm(sig[:,i],2)/np.linalg.norm(sig[:,i] - temp2[:,i],2))\n",
    "        print(f'SNDR: {SNDR:.2f} dB \\n')\n",
    "\n",
    "        #plot an arbitrary part of the signals on different scales\n",
    "        if (plot==True): \n",
    "            \n",
    "            t = np.linspace(0,sig.shape[0]/Fs, int(sig.shape[0])) # time \n",
    "\n",
    "            fig,axs = plt.subplots(4,1, figsize=(8, 8))\n",
    "            axs[0].plot(t[2000:2020],   sig[2000:2020,0])\n",
    "            axs[0].plot(t[2000:2020], temp2[2000:2020,0])\n",
    "\n",
    "            axs[1].plot(t[2000:2120],   sig[2000:2120,0])\n",
    "            axs[1].plot(t[2000:2120], temp2[2000:2120,0])\n",
    "\n",
    "            axs[2].plot(t[:5000],   sig[:5000,0])\n",
    "            axs[2].plot(t[:5000], temp2[:5000,0])\n",
    "\n",
    "            axs[3].plot(t,   sig[:,0])\n",
    "            axs[3].plot(t, temp2[:,0])\n",
    "            axs[3].legend(['Original', 'Compressed'])\n",
    "            axs[3].set_xlabel('seconds')\n",
    "            fig.legend(['Original signal', 'Compressed Signal'], loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "            fig.suptitle(f'Compression error on different scales ({alg})')\n",
    "            plt.tight_layout() \n",
    "            plt.show()\n",
    "\n",
    "        return temp2\n",
    "    \n",
    "    elif (alg == 'k'):\n",
    "        print(f\"RCR of {alg}: {rice_k('', train_sig, sig):.2f} \\n\")\n",
    "    elif (alg == 'l'): \n",
    "        print(f\"RCR of {alg}, alpha = 1: {rice_adaptive_l('', train_sig, sig, 1):.2f} \\n\")\n",
    "        print(f\"RCR of {alg}, alpha = 0.5: {rice_adaptive_l('', train_sig, sig, 0.5):.2f} \\n\")\n",
    "        print(f\"RCR of {alg}, alpha = 0: {rice_adaptive_l('', train_sig, sig, 0):.2f} \\n\")\n",
    "    elif (alg == 'i'):\n",
    "        print(f\"RCR of {alg}: {huff_i('', train_sig, sig):.2f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test spatial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCR of e: 32.38\n",
      "SNDR: 67.40 dB \n",
      "\n",
      "RCR of j: 35.52\n",
      "SNDR: 66.49 dB \n",
      "\n",
      "RCR of g: 27.81\n",
      "SNDR: 64.19 dB \n",
      "\n",
      "RCR of h: 39.58\n",
      "SNDR: 64.13 dB \n",
      "\n",
      "RCR of m: 29.96\n",
      "SNDR: 64.41 dB \n",
      "\n",
      "RCR of e: 23.87\n",
      "SNDR: 78.38 dB \n",
      "\n",
      "RCR of j: 28.09\n",
      "SNDR: 77.46 dB \n",
      "\n",
      "RCR of g: 18.55\n",
      "SNDR: 75.19 dB \n",
      "\n",
      "RCR of h: 33.36\n",
      "SNDR: 74.99 dB \n",
      "\n",
      "RCR of m: 20.37\n",
      "SNDR: 75.42 dB \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -121,   -66,  -141, ...,  -184,  -154,  -190],\n",
       "       [ -823,  -456,  -894, ..., -1271, -1062, -1295],\n",
       "       [-2547, -1527, -2549, ..., -3766, -3207, -3744],\n",
       "       ...,\n",
       "       [ 6180,  6549,  3113, ...,  -186,   956,  2225],\n",
       "       [ 5923,  6132,  2757, ...,  -291,   820,  1967],\n",
       "       [ 6067,  5938,  2651, ...,  -208,   693,  1762]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare different spatial methods against each other\n",
    "\n",
    "# Dataset 1\n",
    "# stereo_e\n",
    "result('e', train_sig, sig0, alpha=1) \n",
    "\n",
    "# quadro_j\n",
    "result('j', train_sig, sig0, alpha=1) \n",
    "\n",
    "# dcts_g\n",
    "result('g', train_sig, sig0, alpha=1)\n",
    "\n",
    "# pca_h\n",
    "result('h', train_sig, sig0, alpha=1)\n",
    "\n",
    "# channel mean removal\n",
    "result('m', train_sig, sig0, alpha=1)\n",
    "\n",
    "# Dataset 2\n",
    "# stereo_e\n",
    "result('e', train_sig, sig1, alpha=1) \n",
    "\n",
    "# quadro_j\n",
    "result('j', train_sig, sig1, alpha=1) \n",
    "\n",
    "# dcts_g\n",
    "result('g', train_sig, sig1, alpha=1)\n",
    "\n",
    "# pca_h\n",
    "result('h', train_sig, sig1, alpha=1)\n",
    "\n",
    "# channel mean removal\n",
    "result('m', train_sig, sig1, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test temporal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCR of d: 39.70\n",
      "SNDR: 0.00 dB \n",
      "\n",
      "RCR of f: 41.12\n",
      "SNDR: 64.20 dB \n",
      "\n",
      "RCR of d: 33.39\n",
      "SNDR: 0.00 dB \n",
      "\n",
      "RCR of f: 34.94\n",
      "SNDR: 75.20 dB \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -121,   -66,  -141, ...,  -184,  -154,  -190],\n",
       "       [ -822,  -456,  -895, ..., -1271, -1062, -1296],\n",
       "       [-2546, -1527, -2550, ..., -3766, -3207, -3744],\n",
       "       ...,\n",
       "       [ 6180,  6549,  3113, ...,  -186,   956,  2225],\n",
       "       [ 5923,  6132,  2757, ...,  -292,   820,  1967],\n",
       "       [ 6066,  5937,  2650, ...,  -208,   693,  1761]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare different temporal methods against each other\n",
    "\n",
    "# dpcm_d\n",
    "result('d', train_sig, sig0, alpha=1) \n",
    "#result('cd', train_sig, sig0, alpha=1) \n",
    "\n",
    "# dctt_f\n",
    "result('f', train_sig, sig0, alpha=1) \n",
    "#result('cf', train_sig, sig0, alpha=1) \n",
    "\n",
    "# dpcm_d\n",
    "result('d', train_sig, sig1, alpha=1) \n",
    "#result('cd', train_sig, sig1, alpha=1) \n",
    "\n",
    "# dctt_f\n",
    "result('f', train_sig, sig1, alpha=1) \n",
    "#result('cf', train_sig, sig1, alpha=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test entropy coding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCR of l, alpha = 1: 26.24 \n",
      "\n",
      "RCR of l, alpha = 0.5: 25.91 \n",
      "\n",
      "RCR of l, alpha = 0: 19.41 \n",
      "\n",
      "RCR of i: 17.55 \n",
      "\n",
      "RCR of l, alpha = 1: 14.60 \n",
      "\n",
      "RCR of l, alpha = 0.5: 14.58 \n",
      "\n",
      "RCR of l, alpha = 0: 12.46 \n",
      "\n",
      "RCR of i: 10.55 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare different entropy coding methods against each other\n",
    "\n",
    "# rice_adaptive_l\n",
    "result('l', train_sig, sig0)\n",
    "\n",
    "# huff_i\n",
    "result('i', train_sig, sig0) \n",
    "\n",
    "# rice_adaptive_l\n",
    "result('l', train_sig, sig1)\n",
    "\n",
    "# huff_i\n",
    "result('i', train_sig, sig1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCR of dfj: 44.67\n",
      "SNDR: 36.74 dB \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"cfj_0  = result('cfj' , train_sig, sig0, alpha=0.5, plot=True)\\ncdj_0  = result('cdj' , train_sig, sig0, alpha=0.5, plot=True)\\ncdjf_0 = result('cdjf', train_sig, sig0, alpha=0.5, plot=True)\\n\\ncfj_1  = result('cfj' , train_sig, sig1, alpha=0.5, plot=True)\\ncdj_1  = result('cdj' , train_sig, sig1, alpha=0.5, plot=True)\\ncdjf_1 = result('cdjf', train_sig, sig1, alpha=0.5, plot=True)\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing without c\n",
    "# Dataset 1\n",
    "'''_ = result('h' , train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "_ = result('d' , train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "_ = result('dh', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "_ = result('fe', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "_ = result('de', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "_ = result('dj', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "\n",
    "_ = result('dg', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "_ = result('dm', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "_ = result('fg', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "_ = result('fm', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "\n",
    "_ = result('fhd' , train_sig, sig0, alpha=0.5)\n",
    "_ = result('dhf' , train_sig, sig0, alpha=0.5)\n",
    "_ = result('def' , train_sig, sig0, alpha=0.5)\n",
    "_ = result('dfh' , train_sig, sig0, alpha=0.5)\n",
    "_ = result('djf' , train_sig, sig0, alpha=0.5)\n",
    "_ = result('jf' , train_sig, sig0, alpha=0.5)'''\n",
    "\n",
    "# Dataset 2\n",
    "'''_ = result('h' , train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "_ = result('d' , train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "_ = result('dh', train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "_ = result('fe', train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "_ = result('de', train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "_ = result('dj', train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "\n",
    "_ = result('dg', train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "_ = result('dm', train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "_ = result('fg', train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "_ = result('fm', train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "\n",
    "_ = result('fhd' , train_sig, sig1, alpha=0.5)\n",
    "_ = result('dhf' , train_sig, sig1, alpha=0.5)\n",
    "_ = result('def' , train_sig, sig1, alpha=0.5)\n",
    "_ = result('dfh' , train_sig, sig1, alpha=0.5)\n",
    "_ = result('djf' , train_sig, sig1, alpha=0.5)\n",
    "_ = result('jf' , train_sig, sig1, alpha=0.5)'''\n",
    "\n",
    "\n",
    "# Test with c included\n",
    "'''cfj_0  = result('cfj' , train_sig, sig0, alpha=0.5, plot=True)\n",
    "cdj_0  = result('cdj' , train_sig, sig0, alpha=0.5, plot=True)\n",
    "cdjf_0 = result('cdjf', train_sig, sig0, alpha=0.5, plot=True)\n",
    "\n",
    "cfj_1  = result('cfj' , train_sig, sig1, alpha=0.5, plot=True)\n",
    "cdj_1  = result('cdj' , train_sig, sig1, alpha=0.5, plot=True)\n",
    "cdjf_1 = result('cdjf', train_sig, sig1, alpha=0.5, plot=True)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCR of cdj: 45.35\n",
      "SNDR: 35.66 dB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdj_3  = result('cdj' , train_sig, sig3, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCR of h: 39.68\n",
      "SNDR: 64.13 dB \n",
      "\n",
      "RCR of cd: 44.17\n",
      "SNDR: 30.34 dB \n",
      "\n",
      "RCR of cdh: 48.51\n",
      "SNDR: 25.82 dB \n",
      "\n",
      "RCR of cfe: 48.32\n",
      "SNDR: 56.58 dB \n",
      "\n",
      "RCR of cde: 48.90\n",
      "SNDR: 27.85 dB \n",
      "\n",
      "RCR of cdj: 51.83\n",
      "SNDR: 26.93 dB \n",
      "\n",
      "RCR of cdg: 46.51\n",
      "SNDR: 31.19 dB \n",
      "\n",
      "RCR of cdm: 46.98\n",
      "SNDR: 27.75 dB \n",
      "\n",
      "RCR of cfg: 45.59\n",
      "SNDR: 58.94 dB \n",
      "\n",
      "RCR of cfm: 46.34\n",
      "SNDR: 56.57 dB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "# compare different combinations of methods\n",
    "\n",
    "# Dataset 1\n",
    "'''result('cfhd', train_sig, sig0, alpha=0.5)\n",
    "result('cfe' , train_sig, sig0, alpha=0.5)\n",
    "result('cdhf', train_sig, sig0, alpha=0.5)\n",
    "result('def' , train_sig, sig0, alpha=0.5)\n",
    "result('cdef', train_sig, sig0, alpha=0.5)# Smooth + DPCM + DiffSum + DCT + Rice\")\n",
    "result('de'  , train_sig, sig0, alpha=0.5)\n",
    "result('cde' , train_sig, sig0, alpha=0.5)\n",
    "result('dfh' , train_sig, sig0, alpha=0.5)# Smooth + DPCM + DCT + PCA + Rice\")\n",
    "result('cdfh', train_sig, sig0, alpha=0.5)# Smooth + DPCM + DCT + PCA + Rice\")\n",
    "result('dj'  , train_sig, sig0, alpha=0.5)\n",
    "result('cdj' , train_sig, sig0, alpha=0.5)# Smooth + DPCM + Quadro + Rice\")\n",
    "result('djf' , train_sig, sig0, alpha=0.5)\n",
    "result('cdjf', train_sig, sig0, alpha=0.5)# Smooth + DPCM + Quadro + DCT + Rice\")\n",
    "result('h'   , train_sig, sig0, alpha=0.5)# Smooth + DPCM + Quadro + DCT + Rice\")\n",
    "result('cd'  , train_sig, sig0, alpha=0.5)# Smooth + DPCM + Quadro + DCT + Rice\")\n",
    "result('ch'  , train_sig, sig0, alpha=0.5)# Smooth + DPCM + Quadro + DCT + Rice\")\n",
    "result('chd' , train_sig, sig0, alpha=0.5)# Smooth + DPCM + Quadro + DCT + Rice\")\n",
    "\n",
    "# Dataset 2\n",
    "result('cfhd', train_sig, sig1, alpha=0.5)\n",
    "result('cfe' , train_sig, sig1, alpha=0.5)\n",
    "result('cdhf', train_sig, sig1, alpha=0.5)\n",
    "result('def' , train_sig, sig1, alpha=0.5)\n",
    "result('cdef', train_sig, sig1, alpha=0.5)# Smooth + DPCM + DiffSum + DCT + Rice\")\n",
    "result('de'  , train_sig, sig1, alpha=0.5)\n",
    "result('cde' , train_sig, sig1, alpha=0.5)\n",
    "result('dfh' , train_sig, sig1, alpha=0.5)# Smooth + DPCM + DCT + PCA + Rice\")\n",
    "result('cdfh', train_sig, sig1, alpha=0.5)# Smooth + DPCM + DCT + PCA + Rice\")\n",
    "result('dj'  , train_sig, sig1, alpha=0.5)\n",
    "result('cdj' , train_sig, sig1, alpha=0.5)# Smooth + DPCM + Quadro + Rice\")\n",
    "result('djf' , train_sig, sig1, alpha=0.5)\n",
    "result('cdjf', train_sig, sig1, alpha=0.5)# Smooth + DPCM + Quadro + DCT + Rice\")\n",
    "result('h'   , train_sig, sig1, alpha=0.5)# Smooth + DPCM + Quadro + DCT + Rice\")\n",
    "result('cd'  , train_sig, sig1, alpha=0.5)# Smooth + DPCM + Quadro + DCT + Rice\")\n",
    "result('ch'  , train_sig, sig1, alpha=0.5)# Smooth + DPCM + Quadro + DCT + Rice\")\n",
    "result('chd' , train_sig, sig1, alpha=0.5)# Smooth + DPCM + Quadro + DCT + Rice\")'''\n",
    "\n",
    "# Test -3bit\n",
    "'''\n",
    "# Dataset 1\n",
    "#a_bh   = result('bh'  , train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "#a_bcd  = result('bcd' , train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "#a_bcdh = result('bcdh', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "#a_bcfe = result('bcfe', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "#a_bcde = result('bcde', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "#a_bcdj = result('bcdj', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "\n",
    "# Dataset 2\n",
    "#b_bh   = result('bh'  , train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "#b_bcd  = result('bcd' , train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "#b_bcdh = result('bcdh', train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "#b_bcfe = result('bcfe', train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "#b_bcde = result('bcde', train_sig, sig1, alpha=0.5)#, plot=True)#\n",
    "#b_bcdj = result('bcdj', train_sig, sig1, alpha=0.5)#, plot=True)#'''\n",
    "\n",
    "\n",
    "# Test why dcdj has BIG error\n",
    "#bcdj = result('cdj' , train_sig, sig0, alpha=1, plot=True)#\n",
    "#bcdj = result('bcdj', train_sig, sig0, alpha=1, plot=True)#\n",
    "#bcdj = result('bcd' , train_sig, sig0, alpha=1, plot=True)#\n",
    "#bcdj = result('bdj' , train_sig, sig0, alpha=1, plot=True)#\n",
    "\n",
    "# Test more spatial methods\n",
    "a_bh   = result('h'  , train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "a_bcd  = result('cd' , train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "a_bcdh = result('cdh', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "a_bcfe = result('cfe', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "a_bcde = result('cde', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "a_bcdj = result('cdj', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "\n",
    "a_bcdh = result('cdg', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "a_bcdh = result('cdm', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "a_bcfe = result('cfg', train_sig, sig0, alpha=0.5)#, plot=True)#\n",
    "a_bcfe = result('cfm', train_sig, sig0, alpha=0.5)#, plot=True)#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
